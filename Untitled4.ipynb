{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9H4vDnP8l9/cu3VLVLQpC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ben-Najafloo/Fairness-evaluation/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aif360\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib-btaWAeTwS",
        "outputId": "1c367f8d-cb1e-4555-9e1c-dbc5a60ef390"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from aif360.datasets import StandardDataset\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "\n",
        "def assess_dataset_fairness(data, sensitive_attributes, label_column):\n",
        "    \"\"\"\n",
        "    Evaluate dataset fairness for multiple sensitive attributes.\n",
        "    \"\"\"\n",
        "    fairness_results = {}\n",
        "    for attr in sensitive_attributes:\n",
        "        print(f\"\\n=== Dataset Fairness Metrics for Sensitive Attribute: {attr} ===\")\n",
        "        privileged_groups = [{attr: 1}]\n",
        "        unprivileged_groups = [{attr: 0}]\n",
        "\n",
        "        dataset = StandardDataset(\n",
        "            data, label_name=label_column, favorable_classes=[1],\n",
        "            protected_attribute_names=[attr],\n",
        "            privileged_classes=[[1]]\n",
        "        )\n",
        "\n",
        "        metric = ClassificationMetric(\n",
        "            dataset,\n",
        "            dataset,  # Assuming you want to compare the dataset to itself\n",
        "            unprivileged_groups=unprivileged_groups,\n",
        "            privileged_groups=privileged_groups,\n",
        "        )\n",
        "\n",
        "        # Updated method calls to calculate fairness metrics\n",
        "        fairness_metrics = {\n",
        "            # statistical_parity_difference() has been replaced by mean_difference()\n",
        "            \"Statistical Parity Difference\": metric.statistical_parity_difference(),\n",
        "            \"Disparate Impact\": metric.disparate_impact(),  # This remains the same\n",
        "        }\n",
        "\n",
        "        # Print and store metrics\n",
        "        for metric_name, value in fairness_metrics.items():\n",
        "            print(f\"{metric_name}: {value:.4f}\")\n",
        "        fairness_results[attr] = fairness_metrics\n",
        "\n",
        "    return fairness_results\n",
        "\n",
        "\n",
        "def train_and_evaluate_fairness(data, sensitive_attributes, label_column):\n",
        "    \"\"\"\n",
        "    Train a model and evaluate fairness for multiple sensitive attributes.\n",
        "    \"\"\"\n",
        "    model_results = {}\n",
        "    for attr in sensitive_attributes:\n",
        "        print(f\"\\n=== Model Fairness Metrics for Sensitive Attribute: {attr} ===\")\n",
        "        try:\n",
        "            # Split dataset into train and test sets\n",
        "            train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Preprocess train and test datasets\n",
        "            dataset_train, privileged_groups, unprivileged_groups = preprocess_data(train_data, attr, label_column)\n",
        "            dataset_test, _, _ = preprocess_data(test_data, attr, label_column)\n",
        "\n",
        "            # Train logistic regression model\n",
        "            X_train = pd.DataFrame(dataset_train.features, columns=dataset_train.feature_names)\n",
        "            y_train = dataset_train.labels.ravel()\n",
        "            X_test = pd.DataFrame(dataset_test.features, columns=dataset_test.feature_names)\n",
        "            y_test = dataset_test.labels.ravel()\n",
        "            model = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "            # Predict on test set\n",
        "            predictions = model.predict(X_test)\n",
        "            dataset_test_pred = dataset_test.copy()\n",
        "            dataset_test_pred.labels = predictions\n",
        "\n",
        "            # Compute classification fairness metrics\n",
        "            classification_metric = ClassificationMetric(\n",
        "                dataset_test, dataset_test_pred,\n",
        "                unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups\n",
        "            )\n",
        "\n",
        "            fairness_metrics = {\n",
        "                \"Accuracy\": model.score(X_test, y_test),\n",
        "                \"Equal Opportunity Difference\": classification_metric.equal_opportunity_difference(),\n",
        "                \"Average Odds Difference\": classification_metric.average_odds_difference(),\n",
        "                \"Disparate Impact\": classification_metric.disparate_impact(),\n",
        "            }\n",
        "\n",
        "            # Handle nan values in metrics\n",
        "            for metric, value in fairness_metrics.items():\n",
        "                if isinstance(value, float) and np.isnan(value):\n",
        "                    fairness_metrics[metric] = 0.0  # Replace nan with 0.0\n",
        "\n",
        "            # Print and store metrics\n",
        "            for metric_name, value in fairness_metrics.items():\n",
        "                print(f\"{metric_name}: {value:.4f}\")\n",
        "            model_results[attr] = fairness_metrics\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred for sensitive attribute '{attr}': {e}\")\n",
        "            model_results[attr] = {\n",
        "                \"Accuracy\": 0.0,\n",
        "                \"Equal Opportunity Difference\": 0.0,\n",
        "                \"Average Odds Difference\": 0.0,\n",
        "                \"Disparate Impact\": 0.0,\n",
        "            }\n",
        "\n",
        "    return model_results\n",
        "\n",
        "\n",
        "def preprocess_data(data, sensitive_attribute, label_column):\n",
        "    \"\"\"\n",
        "    Preprocess data for training and fairness evaluation.\n",
        "    \"\"\"\n",
        "    privileged_groups = [{sensitive_attribute: 1}]\n",
        "    unprivileged_groups = [{sensitive_attribute: 0}]\n",
        "    dataset = StandardDataset(\n",
        "        data, label_name=label_column, favorable_classes=[1],\n",
        "        protected_attribute_names=[sensitive_attribute],\n",
        "        privileged_classes=[[1]]\n",
        "    )\n",
        "    return dataset, privileged_groups, unprivileged_groups\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to assess fairness for multiple sensitive attributes.\n",
        "    \"\"\"\n",
        "    # Load dataset\n",
        "    data = load_sample_data()  # Replace with your dataset loading logic\n",
        "    sensitive_attributes = [\"gender\", \"age\"]  # List of sensitive attributes\n",
        "    label_column = \"label\"  # Adjust based on your dataset\n",
        "\n",
        "    # Step 1: Dataset fairness assessment\n",
        "    dataset_fairness = assess_dataset_fairness(data, sensitive_attributes, label_column)\n",
        "\n",
        "    # Step 2: Model fairness evaluation\n",
        "    proceed = input(\"\\nDo you want to evaluate fairness on the trained model? (yes/no): \").lower()\n",
        "    if proceed == \"yes\":\n",
        "        model_fairness = train_and_evaluate_fairness(data, sensitive_attributes, label_column)\n",
        "\n",
        "\n",
        "# Replace `load_sample_data()` with actual dataset loading\n",
        "def load_sample_data():\n",
        "    \"\"\"\n",
        "    Placeholder for dataset loading logic.\n",
        "    Replace this with your own data loading function.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame({\n",
        "        \"gender\": [1, 0, 1, 0, 1],\n",
        "        \"age\": [1, 1, 0, 0, 1],\n",
        "        \"feature1\": [2.5, 3.6, 1.2, 4.3, 3.1],\n",
        "        \"feature2\": [1, 2, 1, 2, 1],\n",
        "        \"label\": [1, 0, 1, 0, 1],\n",
        "    })\n",
        "    return data\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS6ymsd-eQAv",
        "outputId": "23bf9fe4-639c-44a5-dffe-db942cd2551c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Dataset Fairness Metrics for Sensitive Attribute: gender ===\n",
            "Statistical Parity Difference: -1.0000\n",
            "Disparate Impact: 0.0000\n",
            "\n",
            "=== Dataset Fairness Metrics for Sensitive Attribute: age ===\n",
            "Statistical Parity Difference: -0.1667\n",
            "Disparate Impact: 0.7500\n",
            "\n",
            "Do you want to evaluate fairness on the trained model? (yes/no): yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:[1.0] listed but not observed for feature gender\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Model Fairness Metrics for Sensitive Attribute: gender ===\n",
            "Accuracy: 0.0000\n",
            "Equal Opportunity Difference: 0.0000\n",
            "Average Odds Difference: 0.0000\n",
            "Disparate Impact: 0.0000\n",
            "\n",
            "=== Model Fairness Metrics for Sensitive Attribute: age ===\n",
            "Accuracy: 0.0000\n",
            "Equal Opportunity Difference: 0.0000\n",
            "Average Odds Difference: 0.0000\n",
            "Disparate Impact: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return (self.num_pred_positives(privileged=privileged)\n",
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:673: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return (self.num_pred_positives(privileged=privileged)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset\n",
        "    # data = pd.DataFrame({\n",
        "    #     'age': [25, 45, 35, 50, 23, 40, 32, 47, 35, 50, 23, 40, 32, 47, 35, 50, 23, 40, 32, 47],\n",
        "    #     'income': [50000, 80000, 62000, 72000, 52000, 68000, 59000, 77000, 80000, 62000, 72000, 52000, 80000, 62000, 72000, 52000, 80000, 62000, 72000, 52000],\n",
        "    #     'gender': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],  # 0: Female, 1: Male\n",
        "    #     'loan_approved': [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0]  # 1: Approved, 0: Not Approved\n",
        "    # })\n",
        "    # file_path = \"dataset.csv\"  # Replace with the path to your CSV file\n",
        "    # data = pd.read_csv(file_path)\n",
        "\n",
        "    # # Check the dataset structure\n",
        "    # print(data.head())"
      ],
      "metadata": {
        "id": "ErzGfDC6Wun9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}