{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOl+VJYrrODV4tPhzQOiw7a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ben-Najafloo/Fairness-evaluation/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfoCGGw86CVy",
        "outputId": "c8554a1f-fa00-40a4-b25d-ebd2e911c6bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aif360 in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from aif360) (1.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from aif360) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->aif360) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->aif360) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->aif360) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install aif360\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from aif360.datasets import StandardDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Dataset Fairness Evaluation\n",
        "def assess_dataset_fairness(data, sensitive_attribute, label_column):\n",
        "    privileged_group = data[data[sensitive_attribute] == 1]\n",
        "    unprivileged_group = data[data[sensitive_attribute] == 0]\n",
        "\n",
        "    overall_positive_rate = data[label_column].mean()\n",
        "    privileged_rate = privileged_group[label_column].mean()\n",
        "    unprivileged_rate = unprivileged_group[label_column].mean()\n",
        "\n",
        "    # Fairness metrics\n",
        "    statistical_parity_difference = unprivileged_rate - privileged_rate\n",
        "    disparate_impact = (\n",
        "        unprivileged_rate / privileged_rate if privileged_rate > 0 else 0\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"Overall Positive Rate\": overall_positive_rate,\n",
        "        \"Privileged Group Positive Rate\": privileged_rate,\n",
        "        \"Unprivileged Group Positive Rate\": unprivileged_rate,\n",
        "        \"Statistical Parity Difference\": statistical_parity_difference,\n",
        "        \"Disparate Impact\": disparate_impact,\n",
        "    }"
      ],
      "metadata": {
        "id": "DxagiFFJ8oFm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing for AIF360\n",
        "def preprocess_data(data, sensitive_attribute, label_column):\n",
        "    dataset = StandardDataset(\n",
        "        df=data,\n",
        "        label_name=label_column,\n",
        "        favorable_classes=[1],\n",
        "        protected_attribute_names=[sensitive_attribute],\n",
        "        privileged_classes=[[1]]\n",
        "    )\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "80irlYTr8262"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_fairness(data, sensitive_attribute, label_column):\n",
        "    try:\n",
        "        # Split dataset into train and test sets\n",
        "        train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Prepare train and test sets for fairness evaluation\n",
        "        privileged_groups = [{sensitive_attribute: 1}]\n",
        "        unprivileged_groups = [{sensitive_attribute: 0}]\n",
        "        dataset_train = StandardDataset(\n",
        "            train_data, label_name=label_column, favorable_classes=[1],\n",
        "            protected_attribute_names=[sensitive_attribute],\n",
        "            privileged_classes=[[1]]\n",
        "        )\n",
        "        dataset_test = StandardDataset(\n",
        "            test_data, label_name=label_column, favorable_classes=[1],\n",
        "            protected_attribute_names=[sensitive_attribute],\n",
        "            privileged_classes=[[1]]\n",
        "        )\n",
        "\n",
        "        # Train a simple logistic regression model\n",
        "        X_train = pd.DataFrame(dataset_train.features, columns=dataset_train.feature_names)\n",
        "        y_train = dataset_train.labels.ravel()\n",
        "        X_test = pd.DataFrame(dataset_test.features, columns=dataset_test.feature_names)\n",
        "        y_test = dataset_test.labels.ravel()\n",
        "        model = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "\n",
        "        # Predict on test data\n",
        "        predictions = model.predict(X_test)\n",
        "        dataset_test_pred = dataset_test.copy()\n",
        "        dataset_test_pred.labels = predictions\n",
        "\n",
        "        # Compute fairness metrics\n",
        "        classification_metric = ClassificationMetric(\n",
        "            dataset_test, dataset_test_pred,\n",
        "            unprivileged_groups=unprivileged_groups,\n",
        "            privileged_groups=privileged_groups\n",
        "        )\n",
        "\n",
        "        fairness_metrics = {\n",
        "            \"Accuracy\": model.score(X_test, y_test),\n",
        "            \"Equal Opportunity Difference\": classification_metric.equal_opportunity_difference(),\n",
        "            \"Average Odds Difference\": classification_metric.average_odds_difference(),\n",
        "            \"Disparate Impact\": classification_metric.disparate_impact(),\n",
        "        }\n",
        "\n",
        "        # Handle nan values in metrics\n",
        "        for metric, value in fairness_metrics.items():\n",
        "            if isinstance(value, float) and np.isnan(value):\n",
        "                fairness_metrics[metric] = 0.0  # Replace nan with 0.0\n",
        "\n",
        "        return fairness_metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred during model training or fairness evaluation: {e}\")\n",
        "        # Return default fairness metrics in case of error\n",
        "        return {\n",
        "            \"Accuracy\": 0.0,\n",
        "            \"Equal Opportunity Difference\": 0.0,\n",
        "            \"Average Odds Difference\": 0.0,\n",
        "            \"Disparate Impact\": 0.0,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "w__9mIx18_sL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Workflow\n",
        "def main():\n",
        "    # Example dataset\n",
        "    data = pd.DataFrame({\n",
        "        'age': [25, 45, 35, 50, 23, 40, 32, 47, 35, 50, 23, 40, 32, 47, 35, 50, 23, 40, 32, 47],\n",
        "        'income': [50000, 80000, 62000, 72000, 52000, 68000, 59000, 77000, 80000, 62000, 72000, 52000, 80000, 62000, 72000, 52000, 80000, 62000, 72000, 52000],\n",
        "        'gender': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1],  # 0: Female, 1: Male\n",
        "        'loan_approved': [1, 0, 1, 1,1, 0, 1, 1,1, 0, 1, 1,1, 0, 1, 1, 0, 0, 1, 0]\n",
        "    })\n",
        "\n",
        "    # Sensitive attribute and label column\n",
        "    sensitive_attribute = 'gender'\n",
        "    label_column = 'loan_approved'\n",
        "\n",
        "    # Step 1: Evaluate dataset fairness\n",
        "    dataset_fairness = assess_dataset_fairness(data, sensitive_attribute, label_column)\n",
        "    print(\"\\n=== Dataset Fairness Metrics ===\")\n",
        "    for metric, value in dataset_fairness.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    # Ask user if they want to proceed\n",
        "    proceed = input(\"\\nDo you want to evaluate fairness on the trained model? (yes/no): \").strip().lower()\n",
        "    if proceed != 'yes':\n",
        "        print(\"Exiting the process.\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Train model and evaluate fairness\n",
        "    model_fairness = train_and_evaluate_fairness(data, sensitive_attribute, label_column)\n",
        "    print(\"\\n=== Model Fairness Metrics ===\")\n",
        "    for metric, value in model_fairness.items():\n",
        "        print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STGNSjue9ZpW",
        "outputId": "b52839d0-7fc6-42f4-922d-85e2bf5eeaee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Dataset Fairness Metrics ===\n",
            "Overall Positive Rate: 0.6500\n",
            "Privileged Group Positive Rate: 0.4000\n",
            "Unprivileged Group Positive Rate: 0.9000\n",
            "Statistical Parity Difference: 0.5000\n",
            "Disparate Impact: 2.2500\n",
            "\n",
            "Do you want to evaluate fairness on the trained model? (yes/no): yes\n",
            "\n",
            "=== Model Fairness Metrics ===\n",
            "Accuracy: 0.2500\n",
            "Equal Opportunity Difference: 1.0000\n",
            "Average Odds Difference: 0.0000\n",
            "Disparate Impact: 1.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:278: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
            "/usr/local/lib/python3.10/dist-packages/aif360/metrics/classification_metric.py:279: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n"
          ]
        }
      ]
    }
  ]
}